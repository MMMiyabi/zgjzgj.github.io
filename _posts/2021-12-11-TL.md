---
layout:     post
title:      "迁移学习在交叉属性预测中的应用"
subtitle:   ""
date:       2021-12-11 16:21:00
author:     "zgj"
catalog: false
header-style: text
tags: 无
---

## 小数据集的问题

虽然材料数据集一直在增加，但：

不同数据集的数据不能统一

便于测量和计算的数据不多，能训练出高准确率模型的数据不多

现有的数据相对于整个材料研究范围，仍然算小



## 实验思路

训练好的源模型a)通过目标数据集进行微调，然后预测 b)把源模型作为一个特征提取的工具，继而在目标数据集上训练新的ML或DL模型

TL模型与SC模型比较，并与输入改成PA的SC模型比较

对于相同元素组成的不同结构的化合物，只保留最稳定的那一个



## ElemNet

只用元素分数作为输入特征的神经网络，本文中的该网络去掉了dropout层以提高一致性



作者：量子位
链接：https://www.zhihu.com/question/41979241/answer/569974383
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



## **5. 微调模型的方法**

**特征提取**

我们可以将预训练模型当做特征提取装置来使用。具体的做法是，将输出层去掉，然后将剩下的整个网络当做一个固定的特征提取机，从而应用到新的数据集中。

**采用预训练模型的结构**

我们还可以采用预训练模型的结构，但先将所有的权重随机化，然后依据自己的数据集进行训练。

**训练特定层，冻结其他层**

另一种使用预训练模型的方法是对它进行部分的训练。具体的做法是，将模型起始的一些层的权重保持不变，重新训练后面的层，得到新的权重。在这个过程中，我们可以多次进行尝试，从而能够依据结果找到frozen layers和[retrain layers](https://www.zhihu.com/search?q=retrain+layers&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A569974383})之间的最佳搭配。

如何使用与训练模型，是由数据集大小和新旧数据集(预训练的数据集和我们要解决的数据集)之间数据的相似度来决定的。

下图表展示了在各种情况下应该如何使用预训练模型：

![img](https://pic2.zhimg.com/50/v2-42d773365cabb2b151cf5f0b1748a56f_720w.jpg?source=1940ef5c)![img](https://pic2.zhimg.com/80/v2-42d773365cabb2b151cf5f0b1748a56f_720w.jpg?source=1940ef5c)

**场景一：数据集小，数据相似度高(与pre-trained model的训练数据相比而言)**

在这种情况下，因为数据与预训练模型的训练数据相似度很高，因此我们不需要重新训练模型。我们只需要将输出层改制成符合问题情境下的结构就好。

我们使用预处理模型作为模式提取器。

比如说我们使用在ImageNet上训练的模型来辨认一组新照片中的小猫小狗。在这里，需要被辨认的图片与ImageNet库中的图片类似，但是我们的输出结果中只需要两项——猫或者狗。

在这个例子中，我们需要做的就是把dense layer和最终[softmax layer](https://www.zhihu.com/search?q=softmax+layer&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A569974383})的输出从1000个类别改为2个类别。

**场景二：数据集小，数据相似度不高**

在这种情况下，我们可以冻结预训练模型中的前k个层中的权重，然后重新训练后面的n-k个层，当然最后一层也需要根据相应的输出格式来进行修改。

因为数据的相似度不高，重新训练的过程就变得非常关键。而新数据集大小的不足，则是通过冻结预训练模型的前k层进行弥补。

**场景三：数据集大，数据相似度不高**

在这种情况下，因为我们有一个很大的数据集，所以神经网络的训练过程将会比较有效率。然而，因为实际数据与预训练模型的训练数据之间存在很大差异，采用预训练模型将不会是一种高效的方式。

因此最好的方法还是将预处理模型中的权重全都初始化后在新数据集的基础上重头开始训练。

**场景四：数据集大，数据相似度高**

这就是最理想的情况，采用预训练模型会变得非常高效。最好的运用方式是保持模型原有的结构和初始权重不变，随后在新数据集的基础上重新训练。

