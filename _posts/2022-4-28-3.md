---
layout:     post
title:      "深度学习计算框架"
subtitle:   ""
date:       2022-4-28 11:13:00
author:     "zgj"
catalog: true
header-style: text
tags: 机器学习
---



近年来，深度学习在很多机器学习领域都有着非常出色的表现，在图像识别、语音识别、自然语言处理、机器人、网络广告投放、医学自动诊断和金融等领域有着广泛应用。面对繁多的应用场景，深度学习框架有助于建模者节省大量而繁琐的外围工作，更聚焦业务场景和模型设计本身。简单来说，使用深度学习框架进行模型构建有如下两个优势：

- **节省编写大量底层代码的精力：**屏蔽底层实现，用户只需关注模型的逻辑结构。同时，深度学习工具简化了计算，降低了深度学习入门门槛。
- **省去了部署和适配环境的烦恼：**具备灵活的移植性，可将代码部署到CPU/GPU/移动端上，选择具有分布式性能的深度学习工具会使模型训练更高效。

下面将会介绍两个当前最流行的深度学习计算框架，TensorFlow和Pytorch

### TensorFlow

TensorFlow 是 Google 于 2015 年开源的深度学习框架。TensorFlow前身是谷歌的神经网络算法库 DistBelief，由谷歌人工智能团队谷歌大脑（Google Brain）开发和维护，拥有包括 TensorFlow Hub、TensorFlow Lite、TensorFlow Research Cloud 在内的多个项目以及各类应用程序接口。

TensorFlow 让用户可以快速设计深度学习网络，将底层细节进行抽象，而不用耗费大量时间编写底层 CUDA 或 C++ 代码。TensorFlow 在很多方面拥有优异的表现，比如设计神经网络结构的代码的简洁度，分布式深度学习算法的执行效率，还有部署的便利性（能够全面地支持各种硬件和操作系统）。

TensorFlow编程接口支持Python、C++、Java、Go、R和Haskell API的alpha版本。此外，TensorFlow还可在GoogleCloud和AWS中运行。TensorFlow还支持 Windows 7、Windows 10和Windows Server 2016。由于TensorFlow使用C++ Eigen库，所以库可在ARM架构上编译和优化。这也就意味着用户可以在各种服务器和移动设备上部署自己的训练模型，无须执行单独的模型解码器或者加载Python解释器。

TensorFlow构建了活跃的社区，完善的文档体系，大大降低了我们的学习成本，不过社区和文档主要以英文为主，中文支持有待加强。另外，TensorFlow有很直观的计算图可视化呈现。模型能够快速的部署在各种硬件机器上，从高性能的计算机到移动设备，再到更小的更轻量的智能终端。

TensorFlow的优点有：

1. 轻松构建模型：TensorFlow 提供多个抽象级别，因此可以根据自己的需求选择合适的级别。可以使用高阶 Keras API 构建和训练模型，该 API 能够让使用者轻松地开始使用 TensorFlow 和机器学习。如果需要更高的灵活性，则可以借助即刻执行环境进行快速迭代和直观的调试。对于大型机器学习训练任务，还可以使用 Distribution Strategy API 在不同的硬件配置上进行分布式训练，而无需更改模型定义。
2. 随时随地进行可靠的机器学习生产：TensorFlow 提供直接的生产途径。不管是在服务器、边缘设备还是网络上，都可以使用TensorFlow 轻松地训练和部署模型。如果需要完整的生产型机器学习流水线，可以使用 TensorFlow Extended (TFX)。要在移动设备和边缘设备上进行推断，可以使用 TensorFlow Lite。还可以使用 TensorFlow.js 在 JavaScript 环境中训练和部署模型。
3. 强大的研究实验：构建和训练先进的模型，并且不会降低速度或性能。借助 Keras Functional API 和 Model Subclassing API 等功能，TensorFlow 可以帮助使用者灵活地创建复杂拓扑并实现相关控制。

### Pytorch

2017年1月，Facebook人工智能研究院（FAIR）团队在GitHub上开源了PyTorch，并迅速占领GitHub热度榜榜首。PyTorch的历史可追溯到2002年就诞生于纽约大学的Torch。Torch使用了一种不是很大众的语言Lua作为接口。Lua简洁高效，但由于其过于小众，用的人不是很多。在2017年，Torch的幕后团队推出了PyTorch。PyTorch不是简单地封装Lua Torch提供Python接口，而是对Tensor之上的所有模块进行了重构，并新增了最先进的自动求导系统，成为当下最流行的动态图框架。

Pytorch的功能模块主要可以分为张量计算引擎、自动求导机制和神经网络高级接口。张量计算引擎类似 numpy 和 matlab，基本对象是tensor(类比 numpy 中的 ndarray 或 matlab 中的 array)。除提供基于 CPU 的常用操作的实现外，pytorch 还提供了高效的 GPU 实现，这对于深度学习至关重要。自动求导机制在深度学习模型日趋复杂的今天，是学习框架必不可少的模块。pytorch 采用了动态求导机制，使用类似方法的框架包括： chainer，dynet。作为对比，theano，tensorflow 采用静态自动求导机制。Pytorch的神经网络高级接口提供了神经网络中常用的一些网络结构，如全连接层，卷积层，池化层等，便于研究人员很方便的搭建出自己想要的神经网络模型。同时，pytorch 还提供了常用的模型中经常要使用的优化器和各种初始参数。

Pytorch的三大优势：

1) Python优先支持策略：Pytorch主推的特性之一，就是支持python（官方的提法：puts Python first）。因为直接构建自 Python C API，Pytorch从细粒度上直接支持python的访问。相比于原生Python实现，引入的新概念很少，这不仅降低了 python 用户理解的门槛，也能保证代码基本跟原生的 python 实现一致。事实上，开发者可以直接用原生 python 代码扩展 Pytorch 的 operation。
2) 动态图的良好支持：Tensorflow运行必须提前建好静态计算图，然后通过feed和run重复执行建好的图。但是Pytorch却不需要这么麻烦：PyTorch的程序可以在执行时动态构建/调整计算图。相对来说，pytorch具有更好的灵活性。这得益于Pytorch直接基于 python C API 构建的 python 接口。
3) 易于Debug：Pytorch在运行时可以生成动态图，开发者就可以在堆栈跟踪中看到哪一行代码导致了错误。你甚至可以在调试器中停掉解释器并看看某个层会产生什么。

目前国内也有开源的深度学习框架。比如百度于2016年8月开源的PaddlePaddle，是国内AI框架最早的探索与践行者；华为在2019年8月推出新一代全场景AI计算框架MindSpore，并于2020年3月28日开源；还有清华大学自主研发的即时编译深度学习框架Jittor；腾讯的Angel；字节跳动的BytePS等。