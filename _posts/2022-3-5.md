---
layout:     post
title:      "Dynamic Distillation Network for Cross-Domain Few-Shot Recognition with Unlabeled Data"
subtitle:   ""
date:       2022-3-5 10:20:00
author:     "zgj"
catalog: true
header-style: text
tags: 论文阅读
---



动态蒸馏网络用于无标签数据的跨域小样本识别

### Abstract

现有的大多数小样本学习都是基于元学习的方法，但元学习需要源领域和目标领域的数据集相似。

本文要解决的是源领域和目标领域存在巨大差距的跨域小样本学习问题。

如果直接用预训练模型去给目标数据打标签，效果可能不太好。

本文提出的模型，通过计算通过计算来自教师网络的弱增强版本的未标记图像的预测，并与来自学生网络的相同图像的强增强版本相匹配，来实施一致性正则化。教师网络的参数被更新为学生网络参数的指数移动平均值。我们表明，即使在预训练阶段没有对目标特定的类进行训练，所提出的网络也能学习到容易适应目标领域的表示。

### 1 Introduction

深度学习在视觉识别上的成功要归功于数据集足够大。

元学习在相似领域的预测上十分成功，但在极其不同的领域上，复杂的元学习效果还不如传统的预训练和微调。

为有标签的基础数据和无标签的目标数据使用同一个嵌入（模型），在这里有一个问题，就是为什么不单纯只使用无标签的目标数据通过**自监督学习**去训练模型，这样模型肯定更适合于目标数据，不这样做的原因一是因为自监督学习需要大量的数据，二是这样产生的模型效果很难比普通的迁移学习模型效果更好。同时，有研究表明，结合监督学习和无监督学习能提供更多的可转移的表示。也就是结合监督学习和无监督学习的损失可以为目标任务提供更好的表示。

图1表明基础数据很重要，而目标域的数据，即使没有标签，也可以帮助发展更多的目标域表征

图2说明了我们的方法。我们的目标是训练一个特征提取器，它将被用来评估目标数据集上的少量学习性能。为此，我们提出了一种基于动态提炼的方法。学生网络由编码器fs和分类器gs组成，教师网络与学生网络的结构相似（表示为ft和gt）。分类器gs是一个线性层，可以预测基础数据集中样本的类别-logits。我们计算学生的预测和基础数据集上的地面真实标签之间的监督交叉熵损失。对于无标签的目标数据，我们计算教师对一个图像的弱增强版本的预测和学生对同一图像的强增强版本的预测，并优化蒸馏损失以匹配预测结果。我们还在教师的预测中应用锐化，以鼓励学生的低熵预测。监督损失和蒸馏损失都被用来学习学生的权重。教师网络被更新为学生网络的移动平均值。在几张照片的评估中，我们只使用学生编码器fs作为特征提取器，在每个类别的几个例子组成的标记支持图像上学习分类器头，并计算出查询图像的类别预测。

![](https://i.vgy.me/RCPPkO.png)

 我们的目标是训练一个特征提取器，用来评估目标数据集上的少数学习性能。为此，我们提出了一种基于动态提炼的方法。学生网络由编码器fs和分类器gs组成，教师网络与学生网络的结构相似（表示为ft和gt）。分类器gs是一个线性层，可以预测基础数据集中样本的类别-logits。我们计算学生的预测和基础数据集上的地面真实标签之间的监督交叉熵损失。对于无标签的目标数据，我们计算教师对一个图像的弱增强版本的预测和学生对同一图像的强增强版本的预测，并优化蒸馏损失以匹配预测结果。我们还在教师的预测中应用锐化，以鼓励学生的低熵预测。监督损失和蒸馏损失都被用来学习学生的权重。教师网络被更新为学生网络的移动平均值。在几张照片的评估中，我们只使用学生编码器fs作为特征提取器，在已标记的支持图像上学习分类器头，包括 每个类别的几个例子，并计算出查询图像的类别预测。

本文的主要贡献：

提出了一个简单的跨域（大差距）小样本学习；

使用基于动态蒸馏的方法，通过有标签的基础数据和无标签的目标数据来学习目标数据的表征。

### 2 Related Work

#### 小样本学习分类

小样本学习可以分为生成式的，基于度量的，基于适应的。

元学习；

匹配网络使用余弦相似性；

关系网络学习自己的相似性指标；

MAML学习一个好的初始化参数；

原型网络学习一个特征提取器，计算测试图像和支持图像的距离

MataOptNet 使用一个经过判别训练的预测器来学习表征

#### 自训练（Self-training）

训练一个学生网络来模仿教师网络。教师网络用来给无监督数据创造伪标签或软标签。

#### 半监督学习

使用有监督的交叉熵损失和无监督的正则化损失

FixMatch[22]提出了一个简化的模型，它同时优化了已标记样本的交叉熵损失，并使用模型对弱增强的未标记图像的预测生成了伪标签。如果伪标签有足够的信心，该模型就会被训练成用相同图像的强增强版本来预测伪标签。

#### 跨域小样本学习

我们提出了一种动态蒸馏方法，教师网络的参数在训练期间被更新。我们从教师网络中获得对未标记图像的弱增强版本的预测，并优化模型，使从学生网络中获得的同一图像的强增强版本的预测与教师网络的预测相匹配。

### 3 Methodology

教师网络给无标签数据（弱增强版本）打上标签，使其成为强增强版本

使用学生网络去预测强增强版本的数据

教师网络并不同平常的梯度更新，而是根据学生的参数去更新

![](https://i.vgy.me/vQ1MKq.png)

### 4 Experiments

基础数据100类，每类600个数据。目标数据中20%用来训练，其余用来预测。

进行了5-1和5-5实验

基础图像和弱增强的无标签图像，我们使用随机调整大小-裁剪、水平翻转和归一化的增强方法。对于强增强，我们另外使用颜色抖动、高斯模糊和随机灰度变换。

### 5 Analysis

### 6 Conclusion

我们提出了属性感知关系网络（PAR）来解决少许分子属性预测的问题。PAR包含：一个基于图的分子编码器，将分子图的拓扑结构、原子特征和化学键特征编码到分子嵌入中；一个属性感知嵌入函数，获得编码每个任务的上下文信息的属性感知嵌入；以及一个自适应关系图学习模块，构建一个关系图，在类似分子之间有效传播信息。实验结果一致表明，PAR在少量分子性质预测问题上获得了最先进的性能。
未来有几个方向需要探索。在本文中，PAR在生物物理学和生理学分子特性上进行了评估，这些分子特性被建模为分类任务。虽然量子力学和物理化学性质的预测主要是回归任务，但将PAR扩展到处理这些不同层次的分子性质是很有意思的。此外，尽管PAR的目标是少数的分子属性预测，但所提出的属性感知嵌入函数、自适应关系图学习模块和邻居对齐正则器可以帮助提高基于图的分子编码器的一般性能。最后，解释由PAR学习的子结构也是一个有意义的方向。

